# Пункт 1.1: API для визуализации real-time метрик - Анализ и спецификация

## 1. Отличия от текущей реализации

### Текущая реализация:
- Имеется базовый API аналитики по адресу `/api/analytics`
- Реализованы методы получения DAU, воронки конверсии, событий
- Нет специализированного API для веб-дашборда
- Нет реального времени обновления метрик
- Отсутствует WebSocket интеграция
- Агрегация метрик происходит по запросу без автоматического кэширования
- Используется синхронное выполнение запросов

### Планируемая реализация (пункт 1.1):
- Создание специализированного API контроллера `/api/dashboard/metrics`
- Поддержка real-time метрик с возможностью подписки
- Реализация кэширования метрик для быстрого доступа
- Интеграция с WebSocket для push-уведомлений (см. п.2.3 плана)
- Специфичная структура данных для визуализации
- Оптимизация для частого доступа к данным (до 1000+ запросов/мин)

## 2. Варианты реализации

### Вариант 1: REST API с кэшированием
- Реализовать контроллер `/api/dashboard/metrics`
- Использовать Redis для кэширования метрик
- Обновление кэша каждые 10-30 секунд с помощью Spring Scheduler
- Простая реализация, легкая отладка
- Подходит для начальной реализации

### Вариант 2: WebSocket + REST API
- REST API для первоначальной загрузки данных
- WebSocket соединение для real-time обновлений
- Использование Spring WebSocket
- Наиболее подходящий для real-time дашборда
- Позволяет отправлять обновления без запросов от клиента

### Вариант 3: Kafka Streams + WebSocket (продвинутая реализация)
- Использование Kafka Streams для обработки событий в реальном времени
- Агрегация метрик в потоке
- Push уведомления через WebSocket
- Наиболее сложная, но масштабируемая реализация
- Подходит для высоконагруженных систем

## 3. Бизнес-сценарии

### Сценарий 1: Мониторинг ключевых метрик в реальном времени
- **Актор:** Продуктовый менеджер
- **Цель:** Мониторинг DAU, conversion rates, popular items
- **Поток:** 
  1. Продуктовый менеджер открывает дашборд
  2. Система отображает актуальные метрики
  3. Метрики обновляются в реальном времени
  4. Менеджер видит изменения в поведении пользователей
- **Бизнес-ценность:** Быстрое принятие решений на основе актуальных данных

### Сценарий 2: Быстрое реагирование на изменения
- **Актор:** Аналитик/Инженер
- **Цель:** Выявление проблем в воронке конверсии
- **Поток:**
  1. Система отслеживает резкое падение конверсии
  2. Дашборд в реальном времени отображает изменение
  3. Команда получает информацию о проблеме в течение 10 секунд
  4. Быстрое реагирование на проблему
- **Бизнес-ценность:** Снижение потенциальных потерь за счет быстрого реагирования

### Сценарий 3: Операционная эффективность
- **Актор:** Операционный менеджер
- **Цель:** Отслеживание ключевых показателей
- **Поток:**
  1. Операционный менеджер мониторит дашборд
  2. Видит ключевые показатели в одном месте
  3. Принимает быстрые операционные решения
  4. Повышение эффективности за счёт видимости
- **Бизнес-ценность:** Улучшение операционной эффективности за счёт видимости ключевых показателей

## 4. Юзер стори

### Юзер стори 1: Продуктовый менеджер
```
Как продуктовый менеджер
Я хочу видеть актуальные метрики (DAU, конверсия, популярные товары) в реальном времени
Чтобы быстро реагировать на изменения в поведении пользователей
И принимать обоснованные бизнес-решения
```

### Юзер стори 2: Аналитик
```
Как аналитик
Я хочу видеть обновления метрик без перезагрузки страницы
Чтобы отслеживать ключевые показатели без прерываний
И иметь возможность быстро реагировать на аномалии
```

### Юзер стори 3: Инженер
```
Как инженер
Я хочу иметь API с метриками для интеграции с дашбордом
Чтобы строить интерактивную визуализацию данных
И обеспечивать real-time обновления для пользователей
```

## 5. Приемочные тесты

### Тест 1: Получение DAU метрики
```
Дано: Актуальные данные событий в базе
Когда: Пользователь запрашивает /api/dashboard/metrics/dau
Тогда: Возвращается актуальное значение DAU
И значение обновляется каждые 10 секунд
И время отклика < 200 мс
```

### Тест 2: Получение метрики конверсии
```
Дано: Актуальные данные событий в базе
Когда: Пользователь запрашивает /api/dashboard/metrics/conversion
Тогда: Возвращается текущая конверсия
И данные отфильтрованы по последнему часу
И конверсия рассчитана корректно
```

### Тест 3: Получение популярных товаров
```
Дано: Актуальные данные событий в базе
Когда: Пользователь запрашивает /api/dashboard/metrics/popular-items
Тогда: Возвращается список популярных товаров
И товары отсортированы по частоте просмотров
И возвращаются только товары из последнего часа
```

### Тест 4: Real-time обновление (WebSocket)
```
Дано: Подключение к WebSocket на /ws/dashboard
Когда: В систему поступает новое событие
Тогда: Подписчики получают обновление метрик в течение 10 секунд
И обновления отправляются в формате JSON
И соединение остается активным
```

### Тест 5: Кэширование метрик
```
Дано: Запросы к метрикам выполняются часто
Когда: Множество пользователей запрашивают метрики
Тогда: Значения возвращаются из кэша
И нагрузка на базу данных снижена
И время отклика остается < 200 мс (95% случаев)
```

### Тест 6: Ошибки и отказоустойчивость
```
Дано: Проблемы с подсистемой метрик
Когда: Происходит сбой в системе агрегации
Тогда: API возвращает корректный HTTP статус ошибки
И система не падает полностью
И частично доступные данные все еще отображаются
```

### Тест 7: Защита от флуда запросов
```
Дано: Пользователь делает большое количество запросов
Когда: Превышено количество запросов в единицу времени
Тогда: Срабатывает rate limiting
И пользователю возвращается HTTP 429
И система остается стабильной
```

### Тест 8: Аутентификация и авторизация
```
Дано: Неавторизованный пользователь
Когда: Пользователь пытается получить доступ к метрикам
Тогда: Система требует аутентификацию
И возвращается HTTP 401
И конфиденциальные данные защищены
```

## 6. Объемы данных и потоки событий

### Порядок числа записей в БД:
- По умолчанию генератор создает 70 пользователей (config.userCount = 70)
- Каждый пользователь имеет от 1 до 5 сессий (config.minSessionsPerUser = 1, config.maxSessionsPerUser = 5)
- В каждой сессии происходит от 2 до 8 событий (в зависимости от типа пути - частичный или полный)
- В среднем: 70 пользователей × 3 сессии (среднее) × 6 событий (среднее) = примерно 1260 событий

### Поток поступающих данных:
- События генерируются синтетически в рамках сессии, с временными интервалами от секунд до минут между событиями
- При использовании в продакшене, поток зависит от числа активных пользователей
- В плане указана цель "Подготовка к росту нагрузки (планируется 10x увеличение событий)" - это означает, что текущая архитектура должна масштабироваться до 100-1000x от текущего уровня

### Рекомендации по адекватному набору данных для тестового стенда:
- Для начального тестирования: 50-100 пользователей (примерно 300-800 событий)
- Для нагрузочного тестирования: 200-500 пользователей (примерно 1,200-4,000 событий)
- Для тестирования производительности: до 700-1000 пользователей (до 8,000-10,000 событий)
- Для тестирования реального времени: использовать меньшее количество пользователей, но с активной генерацией событий в реальном времени с помощью повторяющегося вызова API

## 7. Описание Kafka Streams

### Что такое Kafka Streams:
Kafka Streams - это клиентская библиотека для обработки и анализа данных в реальном времени из Apache Kafka. Это мощный инструмент для построения масштабируемых приложений потоковой обработки, позволяющий обрабатывать потоки событий в режиме реального времени.

### Основные особенности Kafka Streams:
- **Легковесная библиотека**: Kafka Streams представляет собой Java-библиотеку, которая легко интегрируется в приложения без необходимости установки отдельных кластеров
- **Обработка в реальном времени**: Позволяет обрабатывать данные сразу при их поступлении без задержек, характерных для batch-обработки
- **Масштабируемость**: Поддерживает горизонтальное масштабирование с автоматическим перераспределением нагрузки между экземплярами приложений
- **Надежность**: Обеспечивает обработку с гарантией "exactly-once", что критично для точных аналитических метрик
- **Интеграция с Kafka**: Тесная интеграция с Apache Kafka позволяет избежать лишних сетевых вызовов и обеспечивает эффективную обработку

### Архитектура Kafka Streams:
- **Streams**: Основная абстракция для определения топологии обработки потока данных
- **KStream**: Представляет поток данных как последовательность записей (record stream), где каждая запись имеет ключ и значение
- **KTable**: Представляет таблицу или изменяющийся набор данных с сопоставленными ключами (changelog stream)
- **Processor API**: Низкоуровневый API для создания сложных топологий обработки
- **DSL (Domain Specific Language)**: Высокоуровневый API для простого определения потоков обработки данных

### Применение в контексте FoodTrack:
- **Реальное время агрегации метрик**: Обработка событий в режиме реального времени для немедленного обновления DAU, конверсии и других показателей
- **Создание окон данных**: Использование time windows для агрегации событий за определенные интервалы (например, последние 10 секунд, последние 5 минут)
- **Обнаружение аномалий**: Мгновенное выявление необычного поведения пользователей или падений конверсии
- **Обогащение данных**: Добавление дополнительной информации к событиям при их обработке
- **Создание производных потоков**: Генерация новых потоков данных для различных аналитических целей

### Интеграция с WebSocket:
- Kafka Streams может обрабатывать события и агрегировать метрики
- Обновленные метрики могут быть отправлены в Redis или напрямую через WebSocket клиентам дашборда
- Обеспечивает быструю реакцию на изменения с минимальной задержкой

### Преимущества для FoodTrack:
- **Масштабируемость**: Возможность обработки увеличенного потока событий (10x, как указано в плане)
- **Минимальная задержка**: Обновление метрик в реальном времени с минимальной задержкой
- **Надежность**: Обработка событий с гарантией точности метрик
- **Гибкость**: Возможность создания сложных аналитических вычислений и паттернов поведения